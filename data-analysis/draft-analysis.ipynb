{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    " - [ ] Clean trajectories (How?). Iterpolation, remove outliers (e.g. points outside path)\n",
    " - [ ] Calculate speed for every 1/3 second or something instead of frame-to-frame? It seems like there is a lot of noise (super high speeds), which could be due do video clitches.\n",
    " - [ ] Anotate video with CSV code. This could be usefull to troubleshoot data.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import os\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom functions \n",
    "# from utils import *\n",
    "\n",
    "from modules.utils import *\n",
    "from modules.draw import *\n",
    "from modules.homography import PixelMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PLotting params\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions (move this somewhere else eventually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inline function for one ore two images\n",
    "def imgshow(img, img2 = None):\n",
    "    if img2 is None:\n",
    "        plt.imshow(img)\n",
    "        # plt.title('World view')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(img2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "# Homography plot functions\n",
    "def draw_point(img, point, color, label = None):\n",
    "    img_cp = cp.deepcopy(img)\n",
    "    pcoords = tuple(point)\n",
    "    cv2.circle(img_cp, pcoords, 4, color, -1)\n",
    "    if label is not None:\n",
    "        tcoords = tuple(point + 5)\n",
    "        cv2.putText(img_cp, label, tcoords,  cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "    # ishow(img_cp)\n",
    "    return img_cp\n",
    "\n",
    "\n",
    "def draw_hom_points(img, points_array):\n",
    "    img_cp = cp.deepcopy(img)\n",
    "    # Loop over points\n",
    "    i = 0\n",
    "    for p in points_array:\n",
    "        i += 1\n",
    "        label = 'p' + str(i)\n",
    "        img_cp = draw_point(img_cp, p, (0, 0, 255), label)\n",
    "    return img_cp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tabular data outputed by video-processing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2-sample-30min.csv')\n",
    "\n",
    "# Calculate centroids\n",
    "df['cx'] =  round(df['xi'] + (df['xj'] - df['xi'])/2).astype(int)\n",
    "df['cy'] =  round(df['yi'] + (df['yj'] - df['yi'])/2).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_frame = cv2.imread('data/2-frame.jpg')\n",
    "img_world = cv2.imread('data/2-sat.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgshow(img_frame, img_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homography points defintion: Set the same points in both images and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one instance of PixelMapper to convert video frames to coordinates\n",
    "quad_coords = {\n",
    "#     # Unprojected\n",
    "#     \"lonlat\": np.array([\n",
    "#         [9.035947, 38.853956], # P1 top right\n",
    "#         [9.035794, 38.853338], # P2 top left\n",
    "#         [9.035631, 38.853425], # P3 bottom left\n",
    "#         [9.035782, 38.853971] #  P4 bottom right\n",
    "#     ]),\n",
    "    # UTM\n",
    "    \"lonlat\": np.array([\n",
    "        [998829.59, 483949.29], # P1 top right\n",
    "        [998812.71, 483881.37], # P2 top left\n",
    "        [998794.68, 483890.92], # P3 bottom left\n",
    "        [998811.35, 483950.93] #  P4 bottom right\n",
    "    ]),\n",
    "    \"pixel\": np.array([\n",
    "        [426, 37], #  P1 top right\n",
    "        [119, 121], #  P2 top left\n",
    "        [547, 171], # P3 bottom left\n",
    "        [596, 50] # P4 bottom right\n",
    "    ]),\n",
    "    \"pixel_sat\": np.array([\n",
    "        [648, 322], # P1 top right\n",
    "        [295, 402], # P2 top left\n",
    "        [322, 488], #  P3 bottom left\n",
    "        [661, 413] # P4 bottom right\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Display image points. \n",
    "img_s_points = draw_hom_points(img_world, quad_coords['pixel_sat'])\n",
    "img_f_points = draw_hom_points(img_frame, quad_coords['pixel'])\n",
    "imgshow(img_f_points, img_s_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PixelMapper class converts coordinates in pixels to lat-long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pixel maper instance to convert from video to lat long (and vice versa)\n",
    "pm = PixelMapper(quad_coords[\"pixel\"], quad_coords[\"lonlat\"])\n",
    "\n",
    "# Create pixel maper instance to convert from sat image to lat long (and vice versa)\n",
    "pm_sat = PixelMapper(quad_coords[\"pixel_sat\"], quad_coords[\"lonlat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test trajectory to see if homography is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To do\n",
    "# - Make sure trajectories are in frame order\n",
    "# - Organize this into a function\n",
    "\n",
    "\n",
    "\n",
    "def draw_trajectory(img, trajectory_array, color):\n",
    "    img_cp = cp.deepcopy(img)\n",
    "    for p in range(1, len(trajectory_array)):\n",
    "            cv2.line(img_cp, tuple(trajectory_array[p-1]), tuple(trajectory_array[p]), color, 2)\n",
    "    return img_cp\n",
    "\n",
    "\n",
    "# Create trajectory df\n",
    "car_df = df[df['obj_id'] == 15]\n",
    "\n",
    "t_car = car_df[['cx', 'cy']].to_numpy()\n",
    "\n",
    "# Anotate trajectory on initial video frame\n",
    "img_cf = img_frame.copy()\n",
    "img_cf = draw_trajectory(img_cf, t_car, (0, 0, 255))\n",
    "\n",
    "# # ishow(img_cf)\n",
    "\n",
    "# Transform trajectories to long lat\n",
    "t_car_ll = pm.pixel_to_lonlat(t_car) # t_car created in draft-intersections.py\n",
    "\n",
    "# Transform lat long trajectory into pixels of sat image\n",
    "t_car_s = pm_sat.lonlat_to_pixel(t_car_ll).astype(int)\n",
    "\n",
    "# # Anotate trajectory on sat image\n",
    "img_cs = img_world.copy()\n",
    "img_cs = draw_trajectory(img_cs, t_car_s, (0, 0, 255))\n",
    "\n",
    "imgshow(img_cf, img_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(car_df, x=\"cx\", y=\"cy\", text=\"frame\", log_x=True, size_max=60)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_array = t_car \n",
    "color = (0, 0, 255)\n",
    "img_cp = cp.deepcopy(img_frame)\n",
    "\n",
    "for p in range(1, len(trajectory_array)):\n",
    "    cv2.line(img_cp, tuple(trajectory_array[p-1]), tuple(trajectory_array[p]), color, 2)\n",
    "ishow(img_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set boundaries to exclude objects too far away from the camera since tracking tend to be less precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create new objects in memory\n",
    "bound_overlay = cp.deepcopy(img_frame)\n",
    "bound_image = cp.deepcopy(img_frame)\n",
    "\n",
    "\n",
    "\n",
    "# Frame boundaries\n",
    "boundaries = np.array([\n",
    "    # Camera corners\n",
    "    [0,0], # top left\n",
    "    [0,img_frame.shape[0]], # bottom left\n",
    "    [img_frame.shape[1],img_frame.shape[0]], # bottom right\n",
    "    \n",
    "    # Additional points to determine limits RIGHT to LEFT\n",
    "    [700,100],\n",
    "    [600,75],\n",
    "    [400,35],\n",
    "    [250,30],\n",
    "\n",
    "    ]) \n",
    "\n",
    "alpha = 0.2  # Transparency factor.\n",
    "\n",
    "\n",
    "# Camera field of view polygon\n",
    "bound_poly = cv2.fillPoly(bound_overlay, pts = [boundaries], color =(255,0,0))\n",
    "\n",
    "\n",
    "# Following line overlays transparent rectangle over the image\n",
    "bound_image = cv2.addWeighted(bound_overlay, alpha, bound_image, 1 - alpha, 0)\n",
    "# bound_image = draw_hom_points(bound_image, boundaries)\n",
    "\n",
    "\n",
    "imgshow(bound_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data frame to only points within field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define preliminary east through movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "overlay = cp.deepcopy(img_frame)\n",
    "image_new = cp.deepcopy(img_frame)\n",
    "\n",
    "# x, y, w, h = 10, 10, 10, 10  # Rectangle parameters\n",
    "# cv2.rectangle(overlay, (x, y), (x+w, y+h), (0, 200, 0), -1)  # A filled rectangle\n",
    "\n",
    "# First trajectory area\n",
    "contours1 = np.array([[5,190], # top left \n",
    "                     [350,480], # bottom left\n",
    "                     [400,430], # bottom right\n",
    "                     [50,170]]) # top right\n",
    "# Second trajectory area\n",
    "contours2 = np.array([[430,40], # top left \n",
    "                     [580,100], # bottom left\n",
    "                     [593,70], # bottom right\n",
    "                     [470,35]]) # top right\n",
    "\n",
    "\n",
    "alpha = 0.3  # Transparency factor.\n",
    "poly1 = cv2.fillPoly(overlay, pts = [contours1], color =(0,255,255))\n",
    "poly2 = cv2.fillPoly(overlay, pts = [contours2], color =(255,0,255))\n",
    "\n",
    "\n",
    "# Following line overlays transparent rectangle over the image\n",
    "image_new = cv2.addWeighted(overlay, alpha, image_new, 1 - alpha, 0)\n",
    "\n",
    "imgshow(image_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter only trajectories that match the movement (o try to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trajectory\n",
    "\n",
    "trj_temp = df[df['obj_id'] == 15]; trj_temp\n",
    "\n",
    "p_temp = tuple(trj_temp.iloc[2][['cx','cy']]); p_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_new_cp = cp.deepcopy(image_new)\n",
    "cv2.circle(image_new_cp, tuple(p_temp), radius=1, color=(0, 0, 255), thickness=3)\n",
    "\n",
    "imgshow(image_new_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if any points in the trajectory are in the defined areas. Idea is that if there are points in both, that trajectory is part of a pre defined movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copy image to anotate with trajectory\n",
    "image_new_cp = cp.deepcopy(image_new)\n",
    "\n",
    "# Test each point individually. Try a more efficient way!\n",
    "\n",
    "\n",
    "bol_area1 = []\n",
    "bol_area2 = []\n",
    "\n",
    "for i in range(0, len(trj_temp)):\n",
    "    p_i = tuple(trj_temp.iloc[i][['cx', 'cy']])\n",
    "    \n",
    "    # Test if points in area\n",
    "    bol_area1.append(cv2.pointPolygonTest(contours1, p_i, False))\n",
    "    bol_area2.append(cv2.pointPolygonTest(contours2, p_i, False))\n",
    "\n",
    "    cv2.circle(image_new_cp, tuple(p_i), radius=1, color=(0, 0, 255), thickness=3)\n",
    "#     print(p_i)\n",
    "#     print(bol)\n",
    "\n",
    "# Test if any point in area\n",
    "any(bol_area1)\n",
    "\n",
    "any(bol_area2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgshow(image_new_cp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculate point speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test distance between reference points to see if consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_coords['lonlat'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_coords['lonlat'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "998829.59-998812.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# math.dist(quad_coords['lonlat'][0], quad_coords['lonlat'][1])\n",
    "\n",
    "# quad_coords['lonlat'][0] - quad_coords['lonlat'][1]\n",
    "np.linalg.norm(quad_coords['lonlat'][0] - quad_coords['lonlat'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trajectory df\n",
    "trj_temp = df[df['obj_id'].isin([1,15])]\n",
    "# trj_temp = df.copy()\n",
    "\n",
    "# trj_temp = df[df['obj_id'].isin([15])]\n",
    "\n",
    "\n",
    "t_temp = trj_temp[['cx', 'cy']].to_numpy()\n",
    "\n",
    "\n",
    "# # ishow(img_cf)\n",
    "\n",
    "# Transform trajectories to long lat\n",
    "t_temp_ll = pm.pixel_to_lonlat(t_temp) # t_car created in draft-intersections.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.DataFrame(t_temp_ll)\n",
    "foo.columns = ['c_lat', 'c_long']\n",
    "# foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.concat([trj_temp.reset_index(drop=True), foo.reset_index(drop=True)], axis=1)\n",
    "new_df = new_df.sort_values(['obj_id', 'frame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag variable\n",
    "# shifted = new_df.groupby(\"obj_id\") #.shift(1) \n",
    "# shifted = new_df.shift(1)[['frame', 'obj_id', 'c_lat', 'c_long']]\n",
    "\n",
    "\n",
    "new_df['c_lat_l'] = new_df.groupby(['obj_id'])['c_lat'].shift(1)\n",
    "new_df['c_long_l'] = new_df.groupby(['obj_id'])['c_long'].shift(1)\n",
    "\n",
    "new_df\n",
    "\n",
    "\n",
    "# df_new.join(shifted, rsuffix = '_l')\n",
    "# new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate distance from point to point lag for the whole data\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "foo = cdist(new_df[['c_lat', 'c_long']], new_df[['c_lat_l', 'c_long_l']], 'euclid')\n",
    "new_df['dist_m'] = np.diagonal(foo)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "\n",
    "\n",
    "# Calculate speed\n",
    "fps = 30\n",
    "\n",
    "new_df['speed_ms'] = new_df['dist_m']/(1/fps)\n",
    "new_df['speed_kmh'] = new_df['speed_ms']*3.6\n",
    "new_df[['frame', 'obj_id', 'cx', 'cy', 'c_lat','c_long', 'c_lat_l', 'c_long_l','dist_m', 'speed_ms','speed_kmh']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comaparing two functions\n",
    "# np.linalg.norm(np.array([998792.072463,483877.645084]) - np.array([998792.089436, 483877.619475]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_temp_ll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Use mouse to find points (or try to at least)\n",
    "\n",
    "\n",
    "# Marker and grab position function\n",
    "\n",
    "img = cp.deepcopy(img_frame)\n",
    "mouseX,mouseY = 0,0\n",
    "\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global mouseX,mouseY\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img,(x,y),3,(255,0,0),1)\n",
    "        mouseX,mouseY = x,y\n",
    "        \n",
    "\n",
    "# A window that will capture the mouse click\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', draw_circle)\n",
    "\n",
    "# while(1):\n",
    "#     cv2.imshow('image',img)\n",
    "#     # Kill window if Q is pressed\n",
    "#     k = cv2.waitKey(1) & 0xFF\n",
    "#     if k == ord('q'):\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "#     elif k == ord('a'):\n",
    "#         print(mouseX,mouseY)\n",
    "# print(mouseX,mouseY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
