{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    " - [ ] Clean trajectories (How?). Iterpolation, remove outliers (e.g. points outside path)\n",
    " - [ ] Calculate speed for every 1/3 second or something instead of frame-to-frame? It seems like there is a lot of noise (super high speeds), which could be due do video clitches.\n",
    " - [x] Anotate video with CSV code. This could be usefull to troubleshoot data.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do video processing:\n",
    " - [ ] Drop tracking if they move out of defined filed of view area. This would solve more or less the issue with tracking different objects as the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do cleaning\n",
    "- [ ] If a trajectory goes and comes back, split into 2\n",
    "- [ ] Filter out short trajectories\n",
    "- [ ] Interpolate frames without tracking if trajectory is monotonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do analysis\n",
    " - [ ] Only in trajectory if of a certain class\n",
    " - [ ] Intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom functions \n",
    "# from utils import *\n",
    "\n",
    "from modules.utils import *\n",
    "from modules.draw import *\n",
    "from modules.homography import PixelMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PLotting params\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "# Printing params\n",
    "pd.set_option(\"max_rows\", 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions (move this somewhere else eventually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inline function for one ore two images\n",
    "def imgshow(img, img2 = None):\n",
    "    if img2 is None:\n",
    "        plt.imshow(img)\n",
    "        # plt.title('World view')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(img2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "# Homography plot functions\n",
    "def draw_point(img, point, color, label = None):\n",
    "    img_cp = cp.deepcopy(img)\n",
    "    pcoords = tuple(point)\n",
    "    cv2.circle(img_cp, pcoords, 4, color, -1)\n",
    "    if label is not None:\n",
    "        tcoords = tuple(point + 5)\n",
    "        cv2.putText(img_cp, label, tcoords,  cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "    # ishow(img_cp)\n",
    "    return img_cp\n",
    "\n",
    "\n",
    "def draw_hom_points(img, points_array, label = True):\n",
    "    \"\"\"\n",
    "    Plots all points in an array in a given image\n",
    "    \"\"\"\n",
    "    \n",
    "    img_cp = cp.deepcopy(img)\n",
    "    # Loop over points\n",
    "    i = 0\n",
    "    for p in points_array:\n",
    "        i += 1\n",
    "        if label:\n",
    "            label = 'p' + str(i)\n",
    "        else:\n",
    "            label = None\n",
    "        img_cp = draw_point(img_cp, p, (0, 0, 255), label)\n",
    "    return img_cp\n",
    "\n",
    "\n",
    "# Draw movements trajectories\n",
    "def draw_trajectory(img, trajectory_array, color):\n",
    "    img_cp = cp.deepcopy(img)\n",
    "    for p in range(1, len(trajectory_array)):\n",
    "            cv2.line(img_cp, tuple(trajectory_array[p-1]), tuple(trajectory_array[p]), color, 2)\n",
    "    return img_cp\n",
    "\n",
    "\n",
    "# Plot areas function\n",
    "def plot_polygon(*polygons, image, color =(0,255,255), alpha = 0.3, show = True):\n",
    "    \"\"\"\n",
    "    Takes N polygon arrays and plots them on a given image\n",
    "    \"\"\"\n",
    "    \n",
    "    overlay = cp.deepcopy(image)\n",
    "    image_new = cp.deepcopy(image)\n",
    "\n",
    "    for poly in polygons:\n",
    "        poly_i = cv2.fillPoly(overlay, pts = [poly], color = color)\n",
    "\n",
    "    image_new = cv2.addWeighted(overlay, alpha, image_new, 1 - alpha, 0)\n",
    "    \n",
    "    if show:\n",
    "        imgshow(image_new)\n",
    "    else:\n",
    "        return image_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter points from df if in area. Returns a boolean pandas series \n",
    "def points_in_area(points_df, area):\n",
    "    df_dict = points_df[['cx', 'cy']].to_dict('records')\n",
    "    \n",
    "    # Empty list to store results\n",
    "    bol_field_of_view = []\n",
    "    \n",
    "    # Loop over all points in df\n",
    "    for row in tqdm(df_dict):\n",
    "        # Test if point in area\n",
    "        p_i = tuple([row['cx'], row['cy']])\n",
    "        bol_int_i = cv2.pointPolygonTest(area, p_i, False)\n",
    "\n",
    "        # Convert to boolean (Gambiarra)\n",
    "        if bol_int_i == -1:\n",
    "            bol_i = False\n",
    "        else:\n",
    "            bol_i = True\n",
    "\n",
    "        bol_field_of_view.append(bol_i)\n",
    "    \n",
    "    return pd.Series(bol_field_of_view)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tabular data outputed by video-processing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2-sample-30min.csv')\n",
    "\n",
    "# Calculate centroids\n",
    "df['cx'] =  round(df['xi'] + (df['xj'] - df['xi'])/2).astype(int)\n",
    "df['cy'] =  round(df['yi'] + (df['yj'] - df['yi'])/2).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_frame = cv2.imread('data/2-frame.jpg')\n",
    "img_world = cv2.imread('data/2-sat.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgshow(img_frame, img_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homography points defintion: Set the same points in both images and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one instance of PixelMapper to convert video frames to coordinates\n",
    "quad_coords = {\n",
    "#     # Unprojected\n",
    "#     \"lonlat\": np.array([\n",
    "#         [9.035947, 38.853956], # P1 top right\n",
    "#         [9.035794, 38.853338], # P2 top left\n",
    "#         [9.035631, 38.853425], # P3 bottom left\n",
    "#         [9.035782, 38.853971] #  P4 bottom right\n",
    "#     ]),\n",
    "    # UTM\n",
    "    \"lonlat\": np.array([\n",
    "        [998829.59, 483949.29], # P1 top right\n",
    "        [998812.71, 483881.37], # P2 top left\n",
    "        [998794.68, 483890.92], # P3 bottom left\n",
    "        [998811.35, 483950.93] #  P4 bottom right\n",
    "    ]),\n",
    "    \"pixel\": np.array([\n",
    "        [426, 37], #  P1 top right\n",
    "        [119, 121], #  P2 top left\n",
    "        [547, 171], # P3 bottom left\n",
    "        [596, 50] # P4 bottom right\n",
    "    ]),\n",
    "    \"pixel_sat\": np.array([\n",
    "        [648, 322], # P1 top right\n",
    "        [295, 402], # P2 top left\n",
    "        [322, 488], #  P3 bottom left\n",
    "        [661, 413] # P4 bottom right\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Display image points. \n",
    "img_s_points = draw_hom_points(img_world, quad_coords['pixel_sat'])\n",
    "img_f_points = draw_hom_points(img_frame, quad_coords['pixel'])\n",
    "imgshow(img_f_points, img_s_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PixelMapper class converts coordinates in pixels to lat-long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pixel maper instance to convert from video to lat long (and vice versa)\n",
    "pm = PixelMapper(quad_coords[\"pixel\"], quad_coords[\"lonlat\"])\n",
    "\n",
    "# Create pixel maper instance to convert from sat image to lat long (and vice versa)\n",
    "pm_sat = PixelMapper(quad_coords[\"pixel_sat\"], quad_coords[\"lonlat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test trajectory to see if homography is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To do\n",
    "# - Make sure trajectories are in frame order\n",
    "# - Organize this into a function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create trajectory df\n",
    "car_df = df[df['obj_id'] == 197]\n",
    "\n",
    "t_car = car_df[['cx', 'cy']].to_numpy()\n",
    "\n",
    "# Anotate trajectory on initial video frame\n",
    "img_cf = img_frame.copy()\n",
    "img_cf = draw_trajectory(img_cf, t_car, (0, 0, 255))\n",
    "\n",
    "# # ishow(img_cf)\n",
    "\n",
    "# Transform trajectories to long lat\n",
    "t_car_ll = pm.pixel_to_lonlat(t_car) # t_car created in draft-intersections.py\n",
    "\n",
    "# Transform lat long trajectory into pixels of sat image\n",
    "t_car_s = pm_sat.lonlat_to_pixel(t_car_ll).astype(int)\n",
    "\n",
    "# # Anotate trajectory on sat image\n",
    "img_cs = img_world.copy()\n",
    "img_cs = draw_trajectory(img_cs, t_car_s, (0, 0, 255))\n",
    "\n",
    "imgshow(img_cf, img_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "car_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(car_df, x=\"cx\", y=\"cy\", text=\"frame\", log_x=True, size_max=60)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set boundaries to exclude objects too far away from the camera since tracking tend to be less precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create new objects in memory\n",
    "bound_overlay = cp.deepcopy(img_frame)\n",
    "bound_image = cp.deepcopy(img_frame)\n",
    "\n",
    "\n",
    "\n",
    "# Frame boundaries\n",
    "boundaries = np.array([\n",
    "    # Camera corners\n",
    "    [0,0], # top left\n",
    "    [0,img_frame.shape[0]], # bottom left\n",
    "    [img_frame.shape[1],img_frame.shape[0]], # bottom right\n",
    "    \n",
    "    # Additional points to determine limits RIGHT to LEFT\n",
    "    [700,100],\n",
    "    [600,55],\n",
    "    [430,25],\n",
    "    [250,30],\n",
    "\n",
    "    ]) \n",
    "\n",
    "alpha = 0.2  # Transparency factor.\n",
    "\n",
    "\n",
    "# Camera field of view polygon\n",
    "bound_poly = cv2.fillPoly(bound_overlay, pts = [boundaries], color =(255,0,0))\n",
    "\n",
    "\n",
    "# PLot field of view\n",
    "bound_image = cv2.addWeighted(bound_overlay, alpha, bound_image, 1 - alpha, 0)\n",
    "bound_image = draw_hom_points(bound_image, boundaries, label = False)\n",
    "\n",
    "\n",
    "imgshow(bound_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data frame to only points within field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each point individually. Try a more efficient way!\n",
    "\n",
    "# image_new_cp = cp.deepcopy(bound_image)\n",
    "\n",
    "\n",
    "# Supposedly the most efficient way of looping through a pandas df\n",
    "df_dict = df.to_dict('records')\n",
    "\n",
    "\n",
    "# Empty list to store results\n",
    "bol_field_of_view = []\n",
    "\n",
    "# Loop over all points in df\n",
    "for row in tqdm(df_dict):\n",
    "    # Test if point in area\n",
    "    p_i = tuple([row['cx'], row['cy']])\n",
    "    bol_int_i = cv2.pointPolygonTest(boundaries, p_i, False)\n",
    "    \n",
    "    # Convert to boolean (Gambiarra)\n",
    "    if bol_int_i == -1:\n",
    "        bol_i = False\n",
    "    else:\n",
    "        bol_i = True\n",
    "    \n",
    "    bol_field_of_view.append(bol_i)\n",
    "#     print(bol_i)\n",
    "#     cv2.circle(image_new_cp, tuple(p_i), radius=1, color=(0, 0, 255), thickness=3)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df[pd.Series(bol_field_of_view)].shape,  df.shape\n",
    "# bool(bol_field_of_view)\n",
    "# # bol_field_of_view\n",
    "# type(bol_field_of_view)\n",
    "# bol_field_of_view.astype('bool')\n",
    "\n",
    "# bol_field_of_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "371069/592934"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movements definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define preliminary east and west through movement. For now, not making the distinction for direction for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First trajectory area\n",
    "contours1 = np.array([[5,190], # top left \n",
    "                     [350,480], # bottom left\n",
    "                     [400,430], # bottom right\n",
    "                     [50,170]]) # top right\n",
    "# Second trajectory area\n",
    "contours2 = np.array([[430,40], # top left \n",
    "                     [580,100], # bottom left\n",
    "                     [593,70], # bottom right\n",
    "                     [470,35]]) # top right\n",
    "\n",
    "plot_polygon(contours1, contours2, image = img_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define preliminary crossing pedestrians movement. Also not caring about order initially, but might increase precision to define multiple areas and define it as crossing any opposite pair in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# First trajectory area\n",
    "ped_area_1 = np.array([[5,170], # top left \n",
    "                       [400,35], # bottom left\n",
    "                       [425,50], # bottom right\n",
    "                       [5,210]]) # top right\n",
    "\n",
    "# Second trajectory area\n",
    "ped_area_2 = np.array([[270,480], # top left \n",
    "                         [550,70], # bottom left\n",
    "                         [580,90], # bottom right\n",
    "                         [370,480]]) # top right\n",
    "\n",
    "plot_polygon(ped_area_1, ped_area_2, image = img_frame)    \n",
    "\n",
    "\n",
    "# foo = plot_polygon(ped_area_1, ped_area_2, image = img_frame , show = False)\n",
    "# foo = draw_hom_points(foo,ped_area_2)\n",
    "# imgshow(foo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter only trajectories that match the movement (o try to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test trajectory\n",
    "\n",
    "trj_temp = df[df['obj_id'] == 15]; trj_temp\n",
    "\n",
    "p_temp = tuple(trj_temp.iloc[2][['cx','cy']]); p_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if any points in the trajectory are in the defined areas. Idea is that if there are points in both, that trajectory is part of a pre defined movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copy image to anotate with trajectory\n",
    "image_new_cp = cp.deepcopy(img_frame)\n",
    "\n",
    "# Test each point individually. Try a more efficient way!\n",
    "\n",
    "\n",
    "bol_area1 = []\n",
    "bol_area2 = []\n",
    "\n",
    "for i in range(0, len(trj_temp)):\n",
    "    p_i = tuple(trj_temp.iloc[i][['cx', 'cy']])\n",
    "    \n",
    "    # Test if points in area\n",
    "    bol_area1.append(cv2.pointPolygonTest(contours1, p_i, False))\n",
    "    bol_area2.append(cv2.pointPolygonTest(contours2, p_i, False))\n",
    "\n",
    "    cv2.circle(image_new_cp, tuple(p_i), radius=1, color=(0, 0, 255), thickness=3)\n",
    "#     print(p_i)\n",
    "#     print(bol)\n",
    "\n",
    "# Test if any point in area\n",
    "any(bol_area1)\n",
    "\n",
    "any(bol_area2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgshow(image_new_cp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[points_in_area(df, ped_area_1)].shape[0]/df.shape[0]\n",
    "\n",
    "def filter_by_movement(area1, area2, df):\n",
    "    \"\"\"\n",
    "    Filter data frame by trajectories that are part of a movement. Defined by \n",
    "    having a at lease one point in both areas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Bool columns\n",
    "    df['area1'] = points_in_area(df, area1)\n",
    "    df['area2'] = points_in_area(df, area2)\n",
    "\n",
    "    \n",
    "    # Get ids of movements\n",
    "    df_agg = df\\\n",
    "        .groupby('obj_id')\\\n",
    "        .agg({'area1' : any, 'area2' : any})\n",
    "    \n",
    "    trajectories_in_movement = df_agg[df_agg['area1'] & df_agg['area2']].index\n",
    "    \n",
    "    return df[df['obj_id'].isin(trajectories_in_movement)]\n",
    "\n",
    "\n",
    "mov1 = filter_by_movement(ped_area_1, ped_area_2, df)\n",
    "mov2 = filter_by_movement(contours1, contours2, df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov2['obj_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_agg = df_cp\\\n",
    "    .groupby('obj_id')\\\n",
    "    .agg({'area1' : any, 'area2' : any})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# len(trajectories_in_movement)\n",
    "\n",
    "# def filter_movements(areas, df):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?? 75% of all points are in area 1???\n",
    "\n",
    "# df[points_in_area(df, ped_area_1)].shape[0]/df.shape[0]\n",
    "# 0.7547146899992242\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculate point speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test distance between reference points to see if consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_coords['lonlat'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_coords['lonlat'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "998829.59-998812.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# math.dist(quad_coords['lonlat'][0], quad_coords['lonlat'][1])\n",
    "\n",
    "# quad_coords['lonlat'][0] - quad_coords['lonlat'][1]\n",
    "np.linalg.norm(quad_coords['lonlat'][0] - quad_coords['lonlat'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trajectory df\n",
    "trj_temp = df[df['obj_id'].isin([1,15])]\n",
    "# trj_temp = df.copy()\n",
    "\n",
    "# trj_temp = df[df['obj_id'].isin([15])]\n",
    "\n",
    "\n",
    "t_temp = trj_temp[['cx', 'cy']].to_numpy()\n",
    "\n",
    "\n",
    "# # ishow(img_cf)\n",
    "\n",
    "# Transform trajectories to long lat\n",
    "t_temp_ll = pm.pixel_to_lonlat(t_temp) # t_car created in draft-intersections.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.DataFrame(t_temp_ll)\n",
    "foo.columns = ['c_lat', 'c_long']\n",
    "# foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.concat([trj_temp.reset_index(drop=True), foo.reset_index(drop=True)], axis=1)\n",
    "new_df = new_df.sort_values(['obj_id', 'frame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag variable\n",
    "# shifted = new_df.groupby(\"obj_id\") #.shift(1) \n",
    "# shifted = new_df.shift(1)[['frame', 'obj_id', 'c_lat', 'c_long']]\n",
    "\n",
    "\n",
    "new_df['c_lat_l'] = new_df.groupby(['obj_id'])['c_lat'].shift(1)\n",
    "new_df['c_long_l'] = new_df.groupby(['obj_id'])['c_long'].shift(1)\n",
    "\n",
    "new_df\n",
    "\n",
    "\n",
    "# df_new.join(shifted, rsuffix = '_l')\n",
    "# new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate distance from point to point lag for the whole data\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "foo = cdist(new_df[['c_lat', 'c_long']], new_df[['c_lat_l', 'c_long_l']], 'euclid')\n",
    "new_df['dist_m'] = np.diagonal(foo)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate speed\n",
    "fps = 30\n",
    "\n",
    "new_df['speed_ms'] = new_df['dist_m']/(1/fps)\n",
    "new_df['speed_kmh'] = new_df['speed_ms']*3.6\n",
    "new_df[['frame', 'obj_id', 'cx', 'cy', 'c_lat','c_long', 'c_lat_l', 'c_long_l','dist_m', 'speed_ms','speed_kmh']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comaparing two functions\n",
    "# np.linalg.norm(np.array([998792.072463,483877.645084]) - np.array([998792.089436, 483877.619475]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_temp_ll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trj_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Use mouse to find points (or try to at least)\n",
    "\n",
    "\n",
    "# Marker and grab position function\n",
    "\n",
    "img = cp.deepcopy(img_frame)\n",
    "mouseX,mouseY = 0,0\n",
    "\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global mouseX,mouseY\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img,(x,y),3,(255,0,0),1)\n",
    "        mouseX,mouseY = x,y\n",
    "        \n",
    "\n",
    "# A window that will capture the mouse click\n",
    "# cv2.namedWindow('image')\n",
    "# cv2.setMouseCallback('image', draw_circle)\n",
    "\n",
    "# while(1):\n",
    "#     cv2.imshow('image',img)\n",
    "#     # Kill window if Q is pressed\n",
    "#     k = cv2.waitKey(1) & 0xFF\n",
    "#     if k == ord('q'):\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "#     elif k == ord('a'):\n",
    "#         print(mouseX,mouseY)\n",
    "# print(mouseX,mouseY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
